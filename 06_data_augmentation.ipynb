{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import tensorflow_hub as hub\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "import os, warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5117 files belonging to 2 classes.\n",
      "Found 5051 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ds_train_ = image_dataset_from_directory(\n",
    "    'train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_valid_ = image_dataset_from_directory(\n",
    "    'valid',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "ds_valid = (\n",
    "    ds_valid_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EuroSAT dataset consists of satellite images of the Earth classified by geographic feature. Below are a number of images from this dataset.\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/LxARYZe.png\" width=300, alt=\"Sixteen satellite images labeled: SeaLake, PermanentCrop, Industrial, Pasture, Residential, and Forest.\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that flips and rotations would be worth trying first since there's no concept of orientation for pictures taken straight overhead. None of the transformations seem likely to confuse classes, however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorFlow Flowers dataset consists of photographs of flowers of several species. Below is a sample.\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/Mt7PR2x.png\" width=300, alt=\"Sixteen images of flowers labeled: roses, tulips, dandelion, and sunflowers\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that horizontal flips and moderate rotations would be worth trying first. Some augmentation libraries include transformations of hue (like red to blue). Since the color of a flower seems distinctive of its class, a change of hue might be less successful. On the other hand, there is suprising variety in cultivated flowers like roses, so, depending on the dataset, this might be an improvement after all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.InputLayer(input_shape=[128, 128, 3]),\n",
    "    \n",
    "    # Data Augmentation\n",
    "    preprocessing.RandomContrast(0.1),\n",
    "    preprocessing.RandomFlip('horizontal'), # flip left-to-right\n",
    "    preprocessing.RandomRotation(0.1),\n",
    "\n",
    "    # Block One\n",
    "    layers.BatchNormalization(renorm=True),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Two\n",
    "    layers.BatchNormalization(renorm=True),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Three\n",
    "    layers.BatchNormalization(renorm=True),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Head\n",
    "    layers.BatchNormalization(renorm=True),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(epsilon=0.01)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=3,\n",
    ")\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning curves in this model stayed close together for much longer than in previous models. This suggests that the augmentation helped prevent overfitting, allowing the model to continue improving.\n",
    "\n",
    "And notice that this model achieved the highest accuracy of all the models in the course! This won't always be the case, but it shows that a well-designed custom convnet can sometimes perform as well or better than a much larger pretrained model. Depending on your application, having a smaller model (which requires fewer resources) could be a big advantage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
